{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c93f9b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification, make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib.colors import ListedColormap\n",
    "from tqdm import tqdm\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn import model_selection\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86d72d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_scale(x):\n",
    "    res = (x - x.mean(axis=0)) / x.std(axis=0)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3f6b0886",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X, Y = iris.data, iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7eb9f11",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = standard_scale(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09fb1199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Найдем собственные векторы и собственные значения\n",
    " \n",
    "covariance_matrix = X.T @ X\n",
    "\n",
    "eig_values, eig_vectors = np.linalg.eig(covariance_matrix)\n",
    "\n",
    "# сформируем список кортежей (собственное значение, собственный вектор)\n",
    "eig_pairs = [(np.abs(eig_values[i]), eig_vectors[:, i]) for i in range(len(eig_values))]\n",
    "\n",
    "# и отсортируем список по убыванию собственных значений\n",
    "eig_pairs.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "#print('Собственные значения и собственные векторы в порядке убывания:')\n",
    "#for i in eig_pairs:\n",
    "#    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "731e2cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "eig_sum = sum(eig_values)\n",
    "var_exp = [(i / eig_sum) * 100 for i in sorted(eig_values, reverse=True)]\n",
    "cum_var_exp = np.cumsum(var_exp)\n",
    "#print(f'Доля дисперсии, описываемая каждой из компонент \\n{var_exp}')\n",
    "\n",
    "# а теперь оценим кумулятивную (то есть накапливаемую) дисперсию при учитывании каждой из компонент\n",
    "#print(f'Кумулятивная доля дисперсии по компонентам \\n{cum_var_exp}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0e125231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сформируем вектор весов из собственных векторов, соответствующих первым двум главным компонентам\n",
    "W = np.hstack([eig_pairs[i][1].reshape(4,1) for i in range(2)])\n",
    "\n",
    "#print(f'Матрица весов W:\\n', W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e85d9ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сформируем новую матрицу \"объекты-признаки\"\n",
    "Z = X.dot(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "785db631",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    \n",
    "    def __init__(self, index, t, true_branch, false_branch):\n",
    "        self.index = index  # индекс признака, по которому ведется сравнение с порогом в этом узле\n",
    "        self.t = t  # значение порога\n",
    "        self.true_branch = true_branch  # поддерево, удовлетворяющее условию в узле\n",
    "        self.false_branch = false_branch  # поддерево, не удовлетворяющее условию в узле\n",
    "        \n",
    "class Leaf:\n",
    "    \n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.prediction = self.predict()\n",
    "        \n",
    "    def predict(self):\n",
    "        # подсчет количества объектов разных классов\n",
    "        classes = {}  # сформируем словарь \"класс: количество объектов\"\n",
    "        for label in self.labels:\n",
    "            if label not in classes:\n",
    "                classes[label] = 0\n",
    "            classes[label] += 1\n",
    "            \n",
    "        # найдем класс, количество объектов которого будет максимальным в этом листе и вернем его    \n",
    "        prediction = max(classes, key=classes.get)\n",
    "        return prediction        \n",
    "\n",
    "    \n",
    "def gini(labels):\n",
    "    #  подсчет количества объектов разных классов\n",
    "    classes = {}\n",
    "    for label in labels:\n",
    "        if label not in classes:\n",
    "            classes[label] = 0\n",
    "        classes[label] += 1\n",
    "    \n",
    "    #  расчет критерия\n",
    "    impurity = 1\n",
    "    for label in classes:\n",
    "        p = classes[label] / len(labels)\n",
    "        impurity -= p ** 2\n",
    "        \n",
    "    return impurity\n",
    "\n",
    "\n",
    "def gain(left_labels, right_labels, root_gini):\n",
    "\n",
    "    # доля выборки, ушедшая в левое поддерево\n",
    "    p = float(left_labels.shape[0]) / (left_labels.shape[0] + right_labels.shape[0])\n",
    "    \n",
    "    return root_gini - p * gini(left_labels) - (1 - p) * gini(right_labels)\n",
    "\n",
    "\n",
    "\n",
    "def split(data, labels, column_index, t):\n",
    "    \n",
    "    left = np.where(data[:, column_index] <= t)\n",
    "    right = np.where(data[:, column_index] > t)\n",
    "        \n",
    "    true_data = data[left]\n",
    "    false_data = data[right]\n",
    "    \n",
    "    true_labels = labels[left]\n",
    "    false_labels = labels[right]\n",
    "        \n",
    "    return true_data, false_data, true_labels, false_labels\n",
    "\n",
    "def find_best_split(data, labels):\n",
    "    \n",
    "    #  обозначим минимальное количество объектов в узле\n",
    "    min_samples_leaf = 3\n",
    "\n",
    "    root_gini = gini(labels)\n",
    "\n",
    "    best_gain = 0\n",
    "    best_t = None\n",
    "    best_index = None\n",
    "    \n",
    "    n_features = data.shape[1]\n",
    "    \n",
    "    for index in range(n_features):\n",
    "        # будем проверять только уникальные значения признака, исключая повторения\n",
    "        t_values = np.unique(data[:, index])\n",
    "        \n",
    "        for t in t_values:\n",
    "            true_data, false_data, true_labels, false_labels = split(data, labels, index, t)\n",
    "            #  пропускаем разбиения, в которых в узле остается менее 5 объектов\n",
    "            if len(true_data) < min_samples_leaf or len(false_data) < min_samples_leaf:\n",
    "                continue\n",
    "            \n",
    "            current_gain = gain(true_labels, false_labels, root_gini)\n",
    "            \n",
    "            #  выбираем порог, на котором получается максимальный прирост качества\n",
    "            if current_gain > best_gain:\n",
    "                best_gain, best_t, best_index = current_gain, t, index\n",
    "\n",
    "    return best_gain, best_t, best_index\n",
    "\n",
    "\n",
    "def build_tree(data, labels):\n",
    "\n",
    "    gain, t, index = find_best_split(data, labels)\n",
    "\n",
    "    #  Базовый случай - прекращаем рекурсию, когда нет прироста в качества\n",
    "    if gain == 0:\n",
    "        return Leaf(data, labels)\n",
    "\n",
    "    true_data, false_data, true_labels, false_labels = split(data, labels, index, t)\n",
    "\n",
    "    # Рекурсивно строим два поддерева\n",
    "    true_branch = build_tree(true_data, true_labels)\n",
    "\n",
    "#     print(time.time(), true_branch)\n",
    "    false_branch = build_tree(false_data, false_labels)\n",
    "    \n",
    "#     print(time.time(), false_branch)\n",
    "    \n",
    "    # Возвращаем класс узла со всеми поддеревьями, то есть целого дерева\n",
    "    return Node(index, t, true_branch, false_branch)\n",
    "\n",
    "\n",
    "\n",
    "def classify_object(obj, node):\n",
    "\n",
    "    #  Останавливаем рекурсию, если достигли листа\n",
    "    if isinstance(node, Leaf):\n",
    "        answer = node.prediction\n",
    "        return answer\n",
    "\n",
    "    if obj[node.index] <= node.t:\n",
    "        return classify_object(obj, node.true_branch)\n",
    "    else:\n",
    "        return classify_object(obj, node.false_branch)\n",
    "    \n",
    "    \n",
    "def predict(data, tree):\n",
    "    \n",
    "    classes = []\n",
    "    for obj in data:\n",
    "        prediction = classify_object(obj, tree)\n",
    "        classes.append(prediction)\n",
    "    return classes\n",
    "\n",
    "def accuracy_metric(actual, predicted):\n",
    "    correct = 0\n",
    "    for i in range(len(actual)):\n",
    "        if actual[i] == predicted[i]:\n",
    "            correct += 1\n",
    "    return correct / float(len(actual)) * 100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a9cb79f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data, train_labels, test_labels = train_test_split(Z, Y, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f203a925",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_tree = build_tree(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5b3e8a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_answers = predict(train_data, my_tree)\n",
    "test_answers = predict(test_data, my_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e21cdf69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy 98.09523809523809\n",
      "Test accuracy 93.33333333333333\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = accuracy_metric(train_labels, train_answers)\n",
    "test_accuracy = accuracy_metric(test_labels, test_answers)\n",
    "\n",
    "print(f'Train accuracy', train_accuracy)\n",
    "print(f'Test accuracy', test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2b4640d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy 98.09523809523809\n",
      "Test accuracy 97.77777777777777\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data, train_labels, test_labels = train_test_split(X, Y, test_size=0.3, random_state=1)\n",
    "my_tree = build_tree(train_data, train_labels)\n",
    "train_answers = predict(train_data, my_tree)\n",
    "test_answers = predict(test_data, my_tree)\n",
    "train_accuracy = accuracy_metric(train_labels, train_answers)\n",
    "test_accuracy = accuracy_metric(test_labels, test_answers)\n",
    "\n",
    "print(f'Train accuracy', train_accuracy)\n",
    "print(f'Test accuracy', test_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
